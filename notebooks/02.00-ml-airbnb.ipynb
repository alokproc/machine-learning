{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project #1\n",
    "by Georgios Karakostas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "One challenge that hosts looking to rent their living space face is determining the optimal nightly rent price. In many areas, renters are presented with a good selection of listings and can filter on criteria like price, number of bedrooms, room type and more. Since AirBnB is a marketplace, the amount a host can charge on a nightly basis is closely linked to the dynamics of the marketplace. \n",
    "\n",
    "As a host, if we try to charge above market price for a living space we'd like to rent, then renters will select more affordable alternatives which are similar to ours. On the other hand, ff we set our nightly rent price too low, we'll miss out on potential revenue.\n",
    "\n",
    "One strategy we could use is to:\n",
    "\n",
    "* Find a few listings that are similar to ours,\n",
    "* average the listed price for the ones most similar to ours,\n",
    "* set our listing price to this calculated average price.\n",
    "\n",
    "The process of discovering patterns in existing data to make a prediction is called **machine learning**. In our case, we want to use data on local listings to predict the optimal price for us to set. In this project, we'll explore a specific machine learning technique called **k-nearest neighbors**, which mirrors the strategy we just described. Before we dive further into machine learning and k-nearest neighbors, let's get familiar with the dataset we'll be working with.\n",
    "\n",
    "While AirBnB doesn't release any data on the listings in their marketplace, a separate group named [Inside AirBnN](https://stackoverflow.com/questions/25692293/inserting-a-link-to-a-webpage-in-an-ipython-notebook) has extracted data on a sample of the listings for many of the major cities on the website. In this project, we'll be working with their dataset from October 3, 2015 on the listings from Washington, D.C., the capital of the United States. Each row in the dataset is a specific listing that's available for renting on AirBnB in the Washington, D.C. area.\n",
    "\n",
    "To make the dataset less cumbersome to work with, we've removed many of the columns in the original dataset and renamed the file to `dc_airbnb.csv`. Here are the columns we kept:\n",
    "\n",
    "* `host_response_rate`: the response rate of the host\n",
    "* `host_acceptance_rate`: number of requests to the host that convert to rentals\n",
    "* `host_listings_count`: number of other listings the host has\n",
    "* `latitude`: latitude dimension of the geographic coordinates\n",
    "* `longitude`: longitude part of the coordinates\n",
    "* `city`: the city the living space resides\n",
    "* `zipcode`: the zip code the living space resides\n",
    "* `state`: the state the living space resides\n",
    "* `accommodates`: the number of guests the rental can accommodate\n",
    "* `room_type`: the type of living space (Private room, Shared room or Entire home/apt\n",
    "* `bedrooms`: number of bedrooms included in the rental\n",
    "* `bathrooms`: number of bathrooms included in the rental\n",
    "* `beds`: number of beds included in the rental\n",
    "* `price`: nightly price for the rental\n",
    "* `cleaning_fee`: additional fee used for cleaning the living space after the guest leaves\n",
    "* `security_deposit`: refundable security deposit, in case of damages\n",
    "* `minimum_nights`: minimum number of nights a guest can stay for the rental\n",
    "* `maximum_nights`: maximum number of nights a guest can stay for the rental\n",
    "* `number_of_reviews`: number of reviews that previous guests have left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Observation\n",
    "Let's read the dataset into Pandas and become more familiar with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_response_rate                  92%\n",
       "host_acceptance_rate                91%\n",
       "host_listings_count                  26\n",
       "accommodates                          4\n",
       "room_type               Entire home/apt\n",
       "bedrooms                              1\n",
       "bathrooms                             1\n",
       "beds                                  2\n",
       "price                           $160.00\n",
       "cleaning_fee                    $115.00\n",
       "security_deposit                $100.00\n",
       "minimum_nights                        1\n",
       "maximum_nights                     1125\n",
       "number_of_reviews                     0\n",
       "latitude                          38.89\n",
       "longitude                      -77.0028\n",
       "city                         Washington\n",
       "zipcode                           20003\n",
       "state                                DC\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dc_listings = pd.read_csv('dc_airbnb.csv')\n",
    "dc_listings.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: K-nearest Neighbors\n",
    "Here's the strategy we want to use:\n",
    "\n",
    "* Find a few similar listings.\n",
    "* Calculate the average nightly rental price of these listings.\n",
    "* Set the average price as the price for our listing.\n",
    "\n",
    "The k-nearest neighbors algorithm is similar to this strategy.\n",
    "\n",
    "There are 2 things we need to unpack in more detail:\n",
    "\n",
    "* The similarity metric.\n",
    "* How to choose the k value.\n",
    "\n",
    "In this project, we'll define what similarity metric we're going to use. Then, we'll implement the **k-nearest neighbors** algorithm and use it to suggest a price for a new, unpriced listing. We'll use a **k value** of 5 for now. Later on, we'll evaluate how good the suggested prices are, choose the optimal **k value**, and more. To that end.\n",
    "\n",
    "### Euclidean Distance\n",
    "\n",
    "The similarity metric works by comparing a fixed set of numerical features, another word for attributes, between 2 observations, or living spaces in our case. When trying to predict a continuous value, like price, the main similarity metric that's used is **Euclidean distance**. Here's the general formula for Euclidean distance:\n",
    "\n",
    "$$d = \\sqrt{(q_1 - p_1)^2 + (q_2 - p_2)^2 + \\ldots + (q_n - p_n)^2}$$\n",
    "\n",
    "where $q_1$ to $q_n$ represent the feature values for one observation and $p_1$ to $p_n$ represent the feature values for the other observation.\n",
    "\n",
    "To begin with, we'll use just one feature to familiarize ourselves with the machine learning workflow. Since we're only using one feature, this is known as the **univariate case**. Here's how the formula looks like for the univariate case:\n",
    "\n",
    "$$d = \\sqrt{(q_1 - p_1)^2}$$\n",
    "\n",
    "The square root and the squared power cancel and the formula simplifies to:\n",
    "\n",
    "$$d = |q_1 - p_1|$$\n",
    "\n",
    "Let's suppose that the living space  we want to rent can accommodate 3 people. We'll first calculate the Euclidean distance, using just the `accommodates` feature, between the first living space in the dataset and \"our own\". To that end, we proceed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "our_acc_value = 3\n",
    "first_living_space_value = dc_listings.iloc[0]['accommodates']\n",
    "first_distance = np.abs(first_living_space_value - our_acc_value)\n",
    "first_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Euclidean distance between the first row in the `dc_listings` Dataframe and our own living space is 1. How do we know if this is high or low? If you look at the Euclidean distance equation itself, the lowest value you can achieve is 0. This happens when the value for the feature is exactly the same for both observations we're comparing. If $p_1 = q_1$, then $|q_1 - p_1|$  which results in $d = 0$. The closer to 0 the distance the more similar the living spaces are.\n",
    "\n",
    "Next, we'll calculate the Euclidean distance between each value in the `accommodates` column from `dc_listings` and the value `3`, which is the number of people our listing accommodates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     2294\n",
       "2      503\n",
       "0      461\n",
       "3      279\n",
       "5       73\n",
       "4       35\n",
       "7       22\n",
       "6       17\n",
       "9       12\n",
       "13       8\n",
       "8        7\n",
       "12       6\n",
       "11       4\n",
       "10       2\n",
       "Name: distance, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_listing = 3\n",
    "dc_listings['distance'] = dc_listings['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "dc_listings['distance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are quite a few, 461 to be precise, living spaces that can accommodate 3 people just like ours. This means the 5 \"nearest neighbors\" we select after sorting all will have a distance value of 0. If we sort by the `distance` column and then just select the first 5 living spaces, we would be biasing the result to the ordering of the dataset.\n",
    "\n",
    "Let's instead randomize the ordering of the dataset and then sort the Dataframe by the `distance` column. This way, all of the living spaces with the same number of bedrooms will still be at the top of the Dataframe but will be in random order across the first 461 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577     $185.00\n",
      "2166    $180.00\n",
      "3631    $175.00\n",
      "71      $128.00\n",
      "1011    $115.00\n",
      "380     $219.00\n",
      "943     $125.00\n",
      "3107    $250.00\n",
      "1499     $94.00\n",
      "625     $150.00\n",
      "Name: price, dtype: object\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "dc_listings = dc_listings.sort_values('distance')\n",
    "print(dc_listings.iloc[0:10]['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Average price\n",
    "\n",
    "Before we can select the 5 most similar living spaces and compute the average price, we need to clean the `price` column. Right now, the `price` column contains comma characters (`,`) and dollar sign characters and is formatted as a text column instead of a numeric one. We need to remove these values and convert the entire column to the `float` datatype. Then, we can calculate the average price. To that end, we proceed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156.6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "mean_price = dc_listings.iloc[0:5]['price'].mean()\n",
    "mean_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've just made our first prediction! Based on the average price of other listings that accommdate 3 people, we should charge **156.6** dollars per night for a guest to stay at our living space. In the next sections, we'll dive into evaluating how good of a prediction this is.\n",
    "\n",
    "To conclude this section, we'll write a more general function that can suggest the optimal price for other values of the `accommodates` column. The `dc_listings` Dataframe has information specific to our living space, e.g. the `distance` column. To save time, we'll reset the `dc_listings` Dataframe to a clean slate and only keep the data cleaning and randomization we did since those weren't unique to the prediction we were making for our living space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Brought along the changes we made to the `dc_listings` Dataframe.\n",
    "dc_listings = pd.read_csv('dc_airbnb.csv')\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "\n",
    "def predict_price(new_listing):\n",
    "    temp_df = dc_listings.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbors = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbors.mean()\n",
    "    return(predicted_price)\n",
    "\n",
    "acc_one = predict_price(1)\n",
    "acc_two = predict_price(2)\n",
    "acc_four = predict_price(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We now have a function that can predict the price for any living space we want to list as long as we know the number of people it can accommodate. The function we wrote represents a **machine learning model**, which means that it outputs a prediction based on the input to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Testing quality of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgioskarakostas/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "train_df = dc_listings.iloc[0:2792]\n",
    "test_df = dc_listings.iloc[2792:]\n",
    "\n",
    "def predict_price(new_listing):\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbor_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbor_prices.mean()\n",
    "    return(predicted_price)\n",
    "\n",
    "test_df['predicted_price'] = test_df['accommodates'].apply(predict_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.22599355531667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgioskarakostas/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_df['error'] = np.absolute(test_df['predicted_price'] - test_df['price'])\n",
    "mae = test_df['error'].mean()\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
